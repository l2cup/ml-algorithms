# -*- coding: utf-8 -*-
"""3a.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F8TVew1SbigHXYy62CL--_SNhDVJdcPt
"""

import os
# Resetting the google colab runtime
os.kill(os.getpid(), 9)

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
# %matplotlib inline

# Commented out IPython magic to ensure Python compatibility.
class KNN:
  
  def __init__(self, nb_features, nb_classes, data, k):
    self.nb_features = nb_features
    self.nb_classes = nb_classes
    self.data = data
    self.k = k
    
    # Gradimo model, X je matrica podataka a Q je vektor koji predstavlja upit.
    self.X = tf.placeholder(shape=(None, nb_features), dtype=tf.float32)
    self.Y = tf.placeholder(shape=(None), dtype=tf.int32)
    self.Q = tf.placeholder(shape=(nb_features), dtype=tf.float32)
    
    # Racunamo kvadriranu euklidsku udaljenost i uzimamo minimalnih k.
    self.dists = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(self.X, self.Q)), 
                                       axis=1)) 
                                  
    _, self.idxs = tf.nn.top_k(-self.dists, self.k)  
    
    self.classes = tf.gather(self.Y, self.idxs)
    self.dists = tf.gather(self.dists, self.idxs)

    # Svaki red mnozimo svojim glasom i sabiramo glasove po kolonama.
    # Posto nam zadatak samo zahteva weightless, filujemo [k] sa 1/k i odmah
    # potom ga reshapujemo.
    w_col = tf.reshape(tf.fill([k], 1/k), (k, 1))
    self.scores = tf.reduce_sum(w_col * tf.one_hot(self.classes, self.nb_classes), axis=0)
    
    # Klasa sa najvise glasova je hipoteza.
    self.hyp = tf.argmax(self.scores)
  
  # Ako imamo odgovore za upit racunamo i accuracy.
  def predict(self, query_data, poc = False):
    
    with tf.Session() as sess:
      sess.run(tf.global_variables_initializer())
      
      nb_queries = query_data['x'].shape[0]
      
      matches = 0
      hyp_vals = []
      accuracy = 0
      for i in range(nb_queries):
        hyp_val = sess.run(self.hyp, feed_dict = {self.X: self.data['x'], 
                                                  self.Y: self.data['y'], 
                                                  self.Q: query_data['x'][i]})
        hyp_vals.append(hyp_val)

        if query_data['y'] is not None:
          actual = query_data['y'][i]
          match = (hyp_val == actual)
          if match:
            matches += 1
          if i % 10 == 0:
            print("Test example: %d/%d| Predicted: %d | Actual: %d | Match: %d"
#                  % (i+1, nb_queries, hyp_val, actual, match))
      
      accuracy = matches / nb_queries
      print("%d matches out of %d examples" % (matches, nb_queries))
      return np.array(hyp_vals), accuracy

nb_features = 4
nb_classes = 2

filename = "Prostate_Cancer.csv"
all_data = np.loadtxt(filename, delimiter=",", dtype="str", skiprows=1)

# Za podatke koje nisu dostupni uzimamo mean i punimo te podatke
for arr in all_data:
  non_NA = list(map(lambda x: x.astype(float),filter(lambda x: x not in {"NA", "M","B"}, arr)))
  mean = sum(non_NA) / len(non_NA)
  for i in range(0, len(arr)):
    if arr[i] == "NA":
      arr[i] = mean
      
key_val = {"M": 0, "B": 1}

data = dict()

data["x"] = np.array([(col[2], col[3], col[4], col[5]) for col in all_data]).astype(float)
data["y"] = np.array([(key_val[col[1]]) for col in all_data]).astype(float)

# Mesanje pomocu random indexa
nb_samples = data["x"].shape[0]
indices = np.random.permutation(nb_samples)
data["x"] = data["x"][indices]
data["y"] = data["y"][indices]

# Deljenje u train i test podatke
test_data = dict()
train_data = dict()

train_data_len = int(0.8 * nb_samples)

train_data["x"] = data["x"][:train_data_len]
train_data["y"] = data["y"][:train_data_len]

test_data["x"] = data["x"][train_data_len:]
test_data["y"] = data["y"][train_data_len:]

tf.reset_default_graph()
k = 3
knn = KNN(nb_features, nb_classes, train_data, k)
_, accuracy = knn.predict(query_data = {"x" : test_data["x"], "y" : test_data["y"]})
print('Test data acurracy is : %.4f' % accuracy)

# Kao sto se ovde moze videti sa k=3 uglavnom dobijamo accuracy koji je
# otprilike 0.8 +- 0.5

tf.reset_default_graph( )
draw = dict()
draw["x"] = np.array([(col[2], col[3]) for col in all_data]).astype(float)
draw["y"] = data["y"]

draw["x"] = draw["x"][indices]

train_data["x"] = draw["x"][:train_data_len]
train_data["y"] = draw["y"][:train_data_len]

test_data["x"] = draw["x"][train_data_len:]
test_data["y"] = draw["y"][train_data_len:]

# Posto ne mozemo da plotujemo sa 4 feature-a ovde uzimamo i zovemo knn na 
# prva dva feature-a. Rezultati sa prva dva feature-a ne odskacu previse 
# od rezultata prvih 4 feature-a sto znaci da je correlation ovde dovoljno 
# dobar da plotujemo borders.

draw_knn = KNN(2, nb_classes, train_data, 3)

step_size = 0.02
# Povecavamo meshgrid da bismo dobili bolji prikaz
# preveliki je za +-1 tako da ostaje +-0.3
x1, x2 = np.meshgrid(np.arange(min(train_data["x"][:, 0]) - 0.3, max(train_data["x"][:, 0]) + 0.3,
                               step_size),
                     np.arange(min(train_data["x"][:, 1]) - 0.3, max(train_data["x"][:, 1]) + 0.3,
                              step_size))

x_feed = np.vstack((x1.flatten(), x2.flatten())).T

pred_vals, _ = draw_knn.predict(query_data = {"x" : x_feed, "y": None})
pred_plot = pred_vals.reshape([x1.shape[0], x1.shape[1]])

classes_cmap = LinearSegmentedColormap.from_list('classes_cmap',
                                                    ['lightblue',
                                                    'lightgreen'])
plt.contourf(x1, x2, pred_plot, cmap=classes_cmap, alpha=0.7)

idxs_0 = train_data['y'] == 0
idxs_1 = train_data['y'] == 1

plt.scatter(train_data['x'][idxs_0, 0], train_data['x'][idxs_0, 1], c='b',
            edgecolors='k', label='M')
plt.scatter(train_data['x'][idxs_1, 0], train_data['x'][idxs_1, 1], c='g',
            edgecolors='k', label='B')
plt.legend()
plt.show()
